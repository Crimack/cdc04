% design_implementation.tex
\newpage
\chapter{Design and Implementation} 
\section{Design}
\label{design}
This body of work is mainly interested in popular classification algorithms, and in trying to use them in a slightly unusual way. It therefore makes sense to extend a package in which these are already implemented, and in which they are easily accessible. The Weka project suits this purpose since it has well maintained, efficient implementations of most machine learning algorithms, handles file I/O, and has both command line and graphical user interfaces. Since Weka is written in Java, it follows that the plugin should also be written in Java.

It also follows that any files which are used for testing should be in either .csv, or .arff format. The former is commonly used in data processing while the latter is a proprietary Weka format which is very similar, but differs in that it contains additional data at the top of the file pertaining to the dataset. Both are supported by Weka, and therefore either is usable.

Since the project relies upon the idea that predictions for missing training data values should converge, it is assumed that the developed classifier will initially only work on nominal data sets. This is because nominal data sets should eventually settle on concrete values (at least when imputed using probabilistic techniques), whilst numeric values are not guaranteed to every settle on a particular value at all. It is more likely that numeric predicitions would just change less and less between iterations, until the changes were miniscule. While it would be possible to implement a solution which stops iterating once a numeric data set only changes to a certain degree, as a proof of concept it is sensible to stick to nominal data.

It is intended that the implemented algorithm will work as follows:
\begin{enumerate}
\item Take a given training set, and make a copy of it
\item Fill the copy set with random, viable values
\item Use the produced data set to train a new model
\item Use the newly trained model to impute values into a new copy of the training set
\item Repeat 3 and 4 until identical data sets are produced by two consecutive iterations
\item Use the model built by the final iteration for classification of a test set
\end{enumerate}

\section{Implementation}
As an existing piece of software is being extended, much of the work to implement the various classifiers to be tested is already done. The main aim of this work is to integrate successfully into Weka as a plugin, and to interface with it as necessary. This plugin will be provided as a zip file containing the implemented algorithm which can be loaded by Weka using its package manager.
\subsection{Weka Architecture}
Weka is a Java package, with a source code layout which looks somewhat like this if unused packages are omitted: \\
\dirtree{%
.1 weka. 
.2 associations. 
.2 attributeSelection. 
.2 classifiers. 
.3 AbstractClassifier. 
.3 IterativeClassifier. 
.3 SingleClassifierEnhancer. 
.2 clusterers. 
.2 core. 
.3 Attribute. 
.3 Capabilities. 
.3 Instance. 
.3 Instances. 
.3 Option. 
.3 Utils. 
.2 datagenerators.
.2 estimators.
.2 experiment.
.2 filters.
.2 gui.
.2 knowledgeflow. }
\hfill \break
Each of these subpackages is reasonably self explanatory. This project is mostly concerned with classifications, and thus code implemented for it lives in the \textit{weka.classifiers} package, although there are some dependcies on \textit{weka.core} since it contains much of the shared code for Weka. Provided that the rest of the project works as intended and the documentation is followed, there is no need to modify or discuss the other packages.

\subsection{weka.core}
From \textit{weka.core}, the following classes are used:

\begin{itemize}
\item \textbf{Attribute} - An Attribute in Weka refers to a single column in a data set. This object is mostly responsible for tracking the column's data type (e.g. nominal, numeric, etc), and other related information common to the entire column.
\item \textbf{Instance} - An Instance is the representation of a single row of data, roughly analogous to a row in a CSV file. Each Instance belongs to a particular Instances object. Each attribute value is stored as a Java double, which is then used in connection with an Attribute object to determine the actual value of an attribute.
\item \textbf{Instances} - An Instances object in Weka is used to represent a complete data set. It is roughly equivalent to the object representation of an ARFF file. It is comprised of a list of Instance objects,  a list of Attribute objects and some other metadata such as the class attribute for the data set and its name.
\item \textbf{Option} - An Option object represents a particular command line parameter, and the way in which it should be handled. This also contains a description to be printed in the help dialog if incorrect parameters are passed to the CLI.
\end{itemize}

\subsection{AbstractClassifier}
\textit{AbstractClassifier} is the class from which all classifiers which make nominal or numeric predictions in Weka [[citation? this is nearly word for word from the Weka javadoc]] are derived from. It provides a number of helpful implementations to prevent code duplication in classifiers, and to ease implementation. A pseudocode description of some notable methods can be seen below:

\begin{footnotesize}
\begin{verbatim}
abstract class AbstractClassifier {
    forName(classifierName, options) {
        return an instance of classifier <classifierName> with options <option>
    }

    runClassifier(classifier, options) {
        run any classifier by passing options to it
    }

    classifyInstance(instance) {
        returns the class which the instance is most 
            likely to belong to as a double in Weka's internal representation
    }

    distributionForInstance(instance) {
        return a list of probabilities for each 
            possibile class value for a given instance
    }

    listOptions() {
        return all of the command line options which 
            a classifier accepts to configure how it will run
    }

    getOptions() {
        return the list of options which a classifier
            is currently set up to run with
    }

    setOptions(options) {
        sets the command line options for a
            classifier to options
    }

    getCapabilities() {
        returns a list of the attribute and class attribute 
            types which are supported by this classifier
    }
}
\end{verbatim}
\end{footnotesize}

There are a number of other utility and stub methods within this abstract class which may prove useful for other people in other cases, but have been omitted from the description above.

\subsection{SingleClassifierEnhancer}
\textit{SingleClassifierEnhancer} is a concrete class which extends from \textit{AbstractClassifier}, and from which the implemented ProjectClassifier extends. Extending from this class gives us a couple of benefits:
\begin{itemize}
\item \textit{SingleClassifierEnhancer} is designed for 'meta' classifiers, or those which wrap another classifier. It already contains an internal classifier and handles passing options to it. This can easily be extended to copy this classifier multiple times with the same options.
\item The internal classifier is already displayed nicely in the Weka GUI. This allows it to be configured via a drop down menu, as shown in figure [[put screenshot here?]].
\item It already handles some edge cases, such as calling the \textit{preExecution()} and \textit{postExecution()} methods of the internal classifier, which handles any specific setup and cleanup needed. These are small edge cases that would be easy to forget about, so extending in this way improves reliability by removing some of the mental overhead of the implementation.
\end{itemize}

\subsection{IterativeClassifier}
\textit{IterativeClassifier} is an Interface which is provided by Weka for 'classifiers which build models of increasing complexity' [[Javadoc citation?]]. It provides three method signatures: 
\begin{footnotesize}
\begin{verbatim}
public initializeClassifier() {
    do setup for the classifier
}

public next() {
    increase in complexity by one step by retraining the model
    return false if finished, or true if another step can be taken
}

public done() {
    stop increasing complexity and do any necessary cleanup
}
\end{verbatim}
\end{footnotesize}
These methods generally come together in the following pattern in a classifier which implements the interface:
\begin{footnotesize}
\begin{verbatim}
public buildClassifier(instances) {
    // some code here 
    initializeClassifier(instances)
    while(next()) {}
    done()
    // some other code here
}
\end{verbatim}
\end{footnotesize}
This means that building the classifier continues until it no longer makes sense to keep doing so, or no gain is achieved. This suits the project's use case, and therefore the interface makes sense to use.

\subsection{Weka Interfaces}
Calling a Weka classifier from the command line (assuming that the Weka jar file is already on the classpath) is reasonably straightforward. The target classifier is firstly called by its full path e.g.  \textit{java weka.classifiers.trees.J48}. Anything which comes after this point is passed to the classifier as an Option object. These are used as parameters to configure the behaviour of a particular classifier, and each class which extends from \textit{AbstractClassifier} generally implements its own specific set of Options through a combination of private variables and specifically named methods. The GUI appears works in much the same way, except that it provides windows with dropdown menus and text fields to allow classifiers and their Options to be configured.  

For example, imagine a given classifier had a private variable named \textit{m\_Example}. In order to expose this to the GUI and CLI it would require getter and setter methods, as well as an \textit{exampleTipText()} method to display help text. Code specifying how to handle this Option would also need to be added to the \textit{getOptions()}, \textit{setOptions()} and \textit{listOptions()} methods. 

[[section too vague / not enough detail?]]

\subsection{StateAnalyser}
The \textit{StateAnalyser} class has been designed to track the progress of the \textit{ProjectClassifier} as it is being trained. It contains a list of the training sets which have been produced by the \textit{next()} method, and records the number of differences between them. All of the methods described below are just utility methods for working with or comparing the training sets which have been produced.

\begin{footnotesize}
\begin{verbatim}
private convertToMatrix(instances) {
    create a matrix
    for each row in the data set {
        turn it into an array of floats
        add that array to the matrix
    }
    return matrix
}

public getNumberDifferences() {
    if at least two training sets recorded {
        convert the two most recent training sets to matrixes
        for each row in both matrices {
            if the two rows differ, increment the difference counter
        }

        return the number of different rows;
    }

    else
        return a negative number to indicate an invalid test;
}


public getNumberIterations() {
    return number of recorded sets
}
\end{verbatim}
\end{footnotesize}
\subsection{ProjectClassifier}
The \textit{ProjetClassifier} class is the implementation of the algorithm described in section \ref{design}. This extends from \textit{SingleClassifierEnhancer} and implements the \textit{IterativeClassifier} interface. It maintains an internal array of classifiers, one for each of the attributes in a data set, and uses these to impute values into the training set as well as to classify test data. It also maintains three copies of training set while building:

\begin{itemize}
\item \textit{original} - a copy of the training set
\item \textit{last} - the last data set produced by imputing missing values, which can be used for retraining during the next iteration
\item \textit{current} - the data set which is currently having its missing values filled in
\end{itemize}

\begin{footnotesize}
\begin{verbatim}
public buildClassifier(instances) {
    record the index of the original class attribute
    take a reference copy of the training set (original)
    find the location of missing data in the training set
    set up the classifier for the first run
    repeat until no change is observed between current and last
    perform any cleanup needed
}

public findMissingAttributes(instances) {
    for each instance in a training set {
        record any values which are missing for later use
    }
}

public initializeClassifier(instances) {
    create new tracker object
    create one classifier object per attribute in the data set
    take two modifiable copies of the training data set (last/current)
    replace any missing data in last using random values
}

public replaceMissingValues(instances) {
    for any each piece of missing data {
        input a random possible value
    }
}

public next() {
    replace last with current
    replace current with a new copy of the training data
    retrain classifiers against last
    for each recorded missing value {
        use trained classifiers to impute missing values in current
    }
    add current to the tracker object
    if (there are no differences between current and last)
        stop iterating
    else   
        iterate again
}

public done() {
    do option specific cleanup
}

public retrainClassifiers(instances) {
    for each attribute in the training set {
        retrain a classifier against that attribute
    }
}
\end{verbatim}
\end{footnotesize}

\textit{ProjetClassifier} also accepts some options, which can be used to configure how it runs:
\begin{itemize}
\item \textbf{maxIterations} (-M number) - Some classifiers may not converge in the way in which we expect, or they make take a very long time to reach this point. This flag allows for a maximum number of training iterations to be set in order to ensure experiments finish in a timely fashion.
\item \textbf{supervised} (-S) - It may be interesting to observe the difference between classifiers which are trained against a training set where the class attribute is trained iteratively along with the rest of the data set against a training set where missing class attribute values are not imputed until the classifier rest of the classifier has converged. This flag allows for the latter case to be tested.
\item \textbf{randomData} (-R) - As a control set during experiments, it make sense to fill a training set with random data and determine whether or not the implemented algorithm outperforms classifiers which are trained against this. This allows this experiment to be performed.
\item \textbf{hiddenVariables} (-N) - See appendix \ref{hidden}.
\end{itemize}
