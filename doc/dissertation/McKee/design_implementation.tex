% design_implementation.tex
\newpage
\chapter{Design and Implementation} 
\section{Design}
This body of work is mainly interested in common classifiers, and in trying to use them in a novel way. It therefore makes sense to extend a package in which these are already implemented, and in which they are easily accessible. The Weka project therefore suits this purpose since it has well maintained, efficient implementations of most machine learning algorithms, as well as handling file I/O, and having both command line and graphical user interfaces. Since these are written in Java, it follows that the plugin should also be written in Java.

It also follows that any files which are used for testing should be in either .csv, or .arff format. The former is commonly used in data processing while the latter is a proprietary Weka format which is very similar, but differs in that it contains additional data at the top of the file pertaining to the dataset. Both are supported by Weka, and therefore either is usable.

Since the project relies upon the idea that predictions for missing training data values should converge, it is assumed that the developed classifier will initially only work on nominal data sets. This is because nominal data sets should eventually settle on concrete values, whilst numeric values are not guaranteed to every settle on a particular value at all. It is more likely that numeric predicitions would just change less and less between iterations, until the changes were miniscule. While it would be possible to implement a solution which stops iterating once a numeric data set only changes to a certain degree, as a proof of concept it is sensible to stick to nominal data.

\section{Implementation}
As an existing piece of software is being extended, much of the work to implement the various classifiers to be tested is already done. The main aim of this work is to integrate successfully into Weka as a plugin, and to interface with it as necessary.
\subsection{Weka Architecture}
Weka is a Java package, with a source code layout which looks somewhat like this if unused packages are omitted: \\
\dirtree{%
.1 weka. 
.2 associations. 
.2 attributeSelection. 
.2 classifiers. 
.3 AbstractClassifier. 
.3 IterativeClassifier. 
.3 SingleClassifierEnhancer. 
.2 clusterers. 
.2 core. 
.3 Attribute. 
.3 Capabilities. 
.3 Instance. 
.3 Instances. 
.3 Option. 
.3 Utils. 
.2 datagenerators.
.2 estimators.
.2 experiment.
.2 filters.
.2 gui.
.2 knowledgeflow. }
\hfill \break
Each of these subpackages is reasonably self explanatory. This project is mostly concerned with classifications, and thus code implemented for it lives in the \textit{weka.classifiers} package, although there are some dependcies on \textit{weka.core} since it contains much of the shared code for Weka. Provided that the rest of the project works as intended and the documentation is followed, there is no need to modify or discuss the other packages.

\subsection{weka.core}
From \textit{weka.core}, the following classes are used:

\begin{itemize}
\item \textbf{Instances} - An Instances object in Weka is used to represent a complete data set. It is roughly equivalent to the object representation of an ARFF file. It is comprised of a list of Instance objects,  a list of Attribute objects and some other metadata such as the class attribute for the data set and its name.
\item \textbf{Attribute} - An Attribute in Weka refers to a single column in a data set. This object is mostly responsible for tracking the column's data type (e.g. nominal, numeric, etc), and other related information common to the entire column.
\item \textbf{Instance} - An Instance is the representation of a single row of data, roughly analogous to a row in a CSV file. Belongs to a particular Instances object. Each attribute value is stored as a Java double, which is then used in connection with an Attribute object to determine the actual value of an attribute.
\item \textbf{Option} - An Option object represents a particular command line parameter, and the way in which it should be handled. This also contains a description to be printed in the help dialog if incorrect parameters are passed to the CLI.
\end{itemize}

\subsection{AbstractClassifier}
\textit{AbstractClassifier} is the class from which all classifiers which make nominal or numeric predictions in Weka (citation? this is nearly word for word from the Weka javadoc) are derived from. It provides a number of helpful implementations to prevent code duplication in classifiers, and to ease implementation. A pseudocode description of some notable methods can be seen below:

\begin{footnotesize}
\begin{verbatim}
abstract class AbstractClassifier {
    forName(classifierName, options) {
        return an instance of classifier <classifierName> with options <option>
    }

    runClassifier(classifier, options) {
        run any classifier by passing options to it
    }

    classifyInstance(instance) {
        returns the class which the instance is most 
            likely to belong to as a double in Weka's internal representation
    }

    distributionForInstance(instance) {
        return a list of probabilities for each 
            possibile class value for a given instance
    }

    listOptions() {
        return all of the command line options which 
            a classifier accepts to configure how it will run
    }

    getOptions() {
        return the list of options which a classifier
            is currently set up to run with
    }

    setOptions(options) {
        sets the command line options for a
            classifier to options
    }

    getCapabilities() {
        returns a list of the attribute and class attribute 
            types which are supported by this classifier
    }
}
\end{verbatim}
\end{footnotesize}

There are a number of other utility and stub methods within this abstract class which may prove useful for other people in other cases, but have been omitted from the description above.

\subsection{SingleClassifierEnhancer}
\textit{SingleClassifierEnhancer} is a concrete class which extends from \textit{AbstractClassifier}, and from which the implemented ProjectClassifier extends. Extending from this class gives us a couple of benefits:
\begin{itemize}
\item \textit{SingleClassifierEnhancer} is designed for 'meta' classifiers, or those which wrap another classifier. It already has an implementation classifier in which it wraps an internal classifier and handles options to it. This can easily be extended to copy this classifier multiple times with the same options
\item The internal classifier is already displayed nicely in the Weka GUI. This allows it to be configured via a drop down menu, as shown in figure (put screenshot here?)
\item It already handles some edge cases, such as calling the \textit{preExecution()} and \textit{postExecution()} methods of the internal classifier, which handles any specific setup and cleanup needed. These are small edge cases that would be easy to forget about, so extending in this way improves reliability by removing some of the implementation overhead.
\end{itemize}

\subsection{IterativeClassifier}
\textit{IterativeClassifier} is an Interface which is provided by Weka for 'classifiers which build models of increasing complexity' (Javadoc citation?). It provides three method signatures: 
\begin{footnotesize}
\begin{verbatim}
public initializeClassifier() {
    do setup for the classifier
}

public next() {
    increase in complexity by one step by retraining the model
    return false if finished, or true if another step can be taken
}

public done() {
    stop increasing complexity and do any necessary cleanup
}
\end{verbatim}
\end{footnotesize}
These methods generally come together in the following pattern in a classifier which implements the interface:
\begin{footnotesize}
\begin{verbatim}
public buildClassifier(instances) {
    // code
    initializeClassifier(instances)
    while(next()) {}
    done()
    // code
}
\end{verbatim}
\end{footnotesize}
This means that building the classifier continues until it no longer makes sense to keep doing so, or no gain is achieved. This suits the project's use case, and therefore the interface makes sense to use.

\subsection{Weka Command Line Interface}
Stuff about passing options to classifiers
\subsection{Weka Graphical User Interface}
Stuff about setter methods etc
\subsection{StateAnalyser}
The \textit{StateAnalyser} class has been designed to track the progress of the \textit{ProjectClassifier} as it is being trained. It contains a list of the training sets which have been produced by the \textit{next()} method, and records the number of differences between them. All of the methods described below are just utility methods for working with or comparing the training sets which have been produced.

\begin{footnotesize}
\begin{verbatim}
private convertToMatrix(instances) {
    create a matrix
    for each row in the data set {
        turn it into an array of floats
        add that array to the matrix
    }
    return matrix
}

public getNumberDifferences() {
    if at least two training sets recorded {
        convert the two most recent training sets to matrixes
        for each row in both matrices {
            if the two rows differ, increment the difference counter
        }

        return the number of different rows;
    }

    else
        return a negative number to indicate an invalid test;
}


public getNumberIterations() {
    return number of recorded sets
}
\end{verbatim}
\end{footnotesize}
\subsection{ProjectClassifier}
Stuff about :
- array of classifiers
- missing value array
- variables used for tracking 
- find missing attributes
- initializeClassifier
- replaceMissingValues
- next
- done 
- retrainClassifiers
- classify / distributionForInstance