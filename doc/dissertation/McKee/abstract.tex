% abstract.tex
\newpage
\begin{abstract}
Data used in the real world has a tendency to be incomplete, with values missing due to problems ranging from clerical error to data corruption. This thesis is concerned with investigating the effects of repeatedly filling in missing values in training data, and especially by doing so using probabilistic methods. The accuracy of using models trained this way is then compared with models trained against the original data set, including the missing values. The accuracy of the implemented method is generally worse than using models which were trained against data sets with missing data, and therefore does not appear useful.
\end{abstract}